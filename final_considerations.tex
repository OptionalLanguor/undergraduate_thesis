\chapter{Conclusion} \label{final_considerations}

%This version goal is to help tailor writing and correct vision mistakes on the project course. It is known by the authors that the content shown here is not perfect, nor is its exposure. But it's intended to collect feedback and suggestions for the final version of this document, such as more recommended literature and different approaches to those presented here and the ones being proposed in the future steps.

%The research is still ongoing. However, it is possible to have conclusions on the progress made. Future steps will also be listed during this chapter.

%\section{Conclusion}\label{conclusao}

A solid version of the proposal was properly elaborated \& developed, and the set goals of this work were achieved. The proposed implementation is capable of receiving stereo camera images and a semantic image to provide in a display a 3D environment with information of the autonomous vehicle sensors and algorithm interpretations. The approach on the characterization of objects in a scene was sufficient to provide input for the 3D environment, and the rendering software implemented with a Data-Oriented Design displays a 3D representation of the autonomous vehicle sensors and autonomous-driving algorithms understanding of a scene. Also, implementation separation in Cloud Analysis and 3D Environment Representation facilitates the individual improvement or substitution of one of them as long as inputs and outputs continue the same. 

However, the limited capability of the used feature extractor to compute information for only one entity of each type in a scene is an important point for improvement and would lead for more variety of test scenarios for representations and also would enable the quantitative metric of bounding box objects in a scene. 

Considering a better performance of the first system, a more elaborate method that could be explored in future work would be to consider clustering entities with the same semantic image information. Thus, still making use of the advantageous semantic information offered by the autonomous-driving algorithm for its decision making, and now considering more than one entity with the same semantic class in a scene. A second point of improvement would be to explore approaches to reduce point cloud noise by using more elaborate depth estimation methods.

To enhance the second system results, future work could involve conducting tests on real embedded systems for autonomous-driving while profiling the software performance, and optimizing it when needed. A parallel approach could involve constructing a display prototype to receive real users feedback and evaluation data. 

Finally, as future research, an approach on surveillance and monitoring could be explored and evaluated. Possibly considering the use of sensors from more than one vehicle connected by network, and also exploring the possibility of map update following the graphical display procedure achieved in this research.

The presented work is a direct contribution to the UNIFEI's Robotics, Intelligent and Complex Systems (RobSIC) Lab \cite{robsic-video-giovani} as a platform with intent of being continuously improved upon.

%\section{Future Work}\label{trabalhos_futuros}


%    With the end of this first stage of development, note some important steps that must be taken in this next research phase. Regarding the first point cloud analysis system, the following points should be worked: Use the variance model to obtain the most efficient object size in the scene; to study ways to generate an approximate plane equivalent to the plane of the street and sidewalk, beside to study ways to deduce the direction of vehicles from the cloud information points we have. Regarding the second system, you must find ways to convert the coordinate format that the environment receives in a format that makes sense in the developed 3D environment. If it is possible, there is also a desire to be able to discriminate different objects within the same category of the semantic image.
